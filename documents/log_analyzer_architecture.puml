@startuml log_analyzer_architecture
title Log Analyzer - Architecture Diagram (RAG Flow Highlighted)
skinparam backgroundColor #FEFEFE
skinparam componentBackgroundColor #F0F0F0
skinparam componentBorderColor #333333
skinparam rectangle {
    BackgroundColor #E8F4F8
    BorderColor #0066CC
}

' ===== UI Layer =====
rectangle "User Interface Layer" {
    component [Streamlit UI\n(app.py)] as StreamlitUI
}

' ===== Application Layer =====
rectangle "Application Layer" {
    component [File Validator\n(validator.py)] as Validator
    component [Analyzer Core\n(analyzer.py)] as Analyzer
    component [Prompt Manager\n(prompts.py)] as Prompts
}

' ===== Data Processing & RAG Pipeline =====
rectangle "Data Processing & RAG Pipeline" #FFE5CC {

    rectangle "Step 1: Ingestion" {
        component [Text Loader\n(LangChain)] as TextLoader
        component [Text Splitter\n(RecursiveCharacterSplitter)] as Splitter
    }

    rectangle "Step 2: Embedding Generation" {
        component [Embedding Model\n(OpenAI/Ollama/Bedrock)] as EmbeddingModel
    }

    rectangle "Step 3: Vector Storage" {
        component [Pinecone Vector Store\n(PineconeVectorStore)] as VectorStore
    }

    rectangle "RAG - Retrieval (R)" #FFCCCC {
        component [Query Embedding] as QueryEmbedding
        component [Similarity Search\n(k=1000)] as SimilaritySearch
    }

    rectangle "RAG - Augmentation (A)" #FFDDCC {
        component [Context Combiner\n(create_stuff_documents_chain)] as ContextCombiner
        component [Prompt Template\n(PromptTemplate)] as PromptEngine
    }

    rectangle "RAG - Generation (G)" #FFFFCC {
        component [LLM Inference\n(ChatOpenAI/ChatOllama/BedrockLLM)] as LLM
        component [Response Generator] as ResponseGen
    }
}

' ===== External Services =====
rectangle "External Services" {
    component [OpenAI API\n(gpt-4o-mini)] as OpenAI
    component [Ollama Local\n(llama3.2:latest)] as Ollama
    component [AWS Bedrock\n(Claude)] as Bedrock
}

rectangle "Vector Database" {
    component [Pinecone\n(Serverless Index)] as PineconeDB
}

' ===== Relationships: UI to Application =====
StreamlitUI --> Validator : validates
StreamlitUI --> Analyzer : initializes

' ===== Relationships: Validation & Ingestion Flow =====
Validator -.-> Analyzer : file OK

Analyzer --> TextLoader : load file
TextLoader --> Splitter : split docs

' ===== Relationships: Embedding & Storage =====
Splitter --> EmbeddingModel : embed chunks
EmbeddingModel --> VectorStore : store vectors
VectorStore --> PineconeDB : persist

' ===== Relationships: Query Processing (RAG) =====
Analyzer --> QueryEmbedding : embed query
QueryEmbedding --> SimilaritySearch : find similar
SimilaritySearch --> ContextCombiner : pass chunks
ContextCombiner --> PromptEngine : format context
PromptEngine --> Prompts : use template

PromptEngine --> LLM : generate
LLM --> ResponseGen : output
ResponseGen --> StreamlitUI : return answer

' ===== External Service Integrations =====
EmbeddingModel -.-> OpenAI : embedding
EmbeddingModel -.-> Ollama : embedding
EmbeddingModel -.-> Bedrock : embedding

LLM -.-> OpenAI : inference
LLM -.-> Ollama : inference
LLM -.-> Bedrock : inference

VectorStore -.-> PineconeDB : index ops

legend right
  Color Coding:
  |<#FFCCCC> RAG Retrieval Phase |
  |<#FFDDCC> RAG Augmentation Phase |
  |<#FFFFCC> RAG Generation Phase |
end legend

@enduml
